# ai_trainer_app.py
import os
import streamlit as st
from PIL import Image
import random
import pandas as pd
from datetime import datetime
from io import BytesIO
from gtts import gTTS
import base64
from openai import OpenAI

# ----------------- Configuration -----------------
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY", ""))
RESULTS_PATH = "results.xlsx"
TRAINING_DATA_PATH = "training_data.xlsx"
GPT_MODEL = os.getenv("GPT_MODEL", "gpt-4o-mini")

st.set_page_config(page_title="AI Project â€” Trainer", layout="wide", page_icon=":wrench:")

# ----------------- Helpers -----------------
def image_to_base64_bytes(file) -> str:
    if file is None:
        return ""
    file.seek(0)
    return base64.b64encode(file.read()).decode("utf-8")

def base64_to_image(b64: str):
    if not b64:
        return None
    return Image.open(BytesIO(base64.b64decode(b64)))

def load_results(path=RESULTS_PATH):
    if os.path.exists(path):
        try:
            return pd.read_excel(path)
        except Exception:
            return pd.DataFrame(columns=["Image Name", "Result", "Time"])
    else:
        return pd.DataFrame(columns=["Image Name", "Result", "Time"])

def save_result(filename, result, path=RESULTS_PATH):
    df = load_results(path)
    new_row = {
        "Image Name": filename,
        "Result": result,
        "Time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
    df.to_excel(path, index=False)
    return df

def results_to_excel_bytes(df):
    buffer = BytesIO()
    df.to_excel(buffer, index=False)
    buffer.seek(0)
    return buffer.getvalue()

def clear_results(path=RESULTS_PATH):
    if os.path.exists(path):
        os.remove(path)

# Training data functions
def load_training_data(path=TRAINING_DATA_PATH):
    if os.path.exists(path):
        try:
            return pd.read_excel(path)
        except Exception:
            # if file corrupted, return empty template
            return pd.DataFrame(columns=[
                "Ø§Ø³Ù… Ø§Ù„Ø¹ÙŠØ¨", "Ø§Ù„ÙˆØµÙ", "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·ÙˆØ±Ø©", "ØªÙ… Ø¹Ù„ÙŠÙ‡ ØªØ¬Ù…ÙŠØ¹",
                "Ø§Ù„Ø¹Ø¨ÙˆØ© Ø³Ù„ÙŠÙ…Ø©", "Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø³Ù„ÙŠÙ…Ø©",
                "image_good_b64", "image_defect_b64",
                "ai_guess", "user_correction", "correction_reason", "timestamp"
            ])
    else:
        return pd.DataFrame(columns=[
            "Ø§Ø³Ù… Ø§Ù„Ø¹ÙŠØ¨", "Ø§Ù„ÙˆØµÙ", "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·ÙˆØ±Ø©", "ØªÙ… Ø¹Ù„ÙŠÙ‡ ØªØ¬Ù…ÙŠØ¹",
            "Ø§Ù„Ø¹Ø¨ÙˆØ© Ø³Ù„ÙŠÙ…Ø©", "Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø³Ù„ÙŠÙ…Ø©",
            "image_good_b64", "image_defect_b64",
            "ai_guess", "user_correction", "correction_reason", "timestamp"
        ])

def save_training_row(row_dict, path=TRAINING_DATA_PATH):
    df = load_training_data(path)
    df = pd.concat([df, pd.DataFrame([row_dict])], ignore_index=True)
    df.to_excel(path, index=False)

# Build few-shot examples from recent corrected rows
def build_few_shot_examples(n_examples=3):
    df = load_training_data()
    examples = []
    if df.empty:
        return examples
    df_valid = df.dropna(subset=["user_correction"]).tail(n_examples)
    for _, r in df_valid.iterrows():
        ex = {
            "description": str(r.get("Ø§Ù„ÙˆØµÙ", "")),
            "ai_guess": str(r.get("ai_guess", "")),
            "correction": str(r.get("user_correction", "")),
            "reason": str(r.get("correction_reason", ""))
        }
        examples.append(ex)
    return examples

# Compose system prompt with few-shot
def compose_system_prompt():
    base = (
        "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ØªØ´Ø®ÙŠØµ Ø¹ÙŠÙˆØ¨ ØµÙ†Ø§Ø¹ÙŠØ© ÙŠØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ù…Ø¯Ø±Ø¨. "
        "Ø¹Ù†Ø¯ ØªØ­Ù„ÙŠÙ„Ùƒ Ù„Ø­Ø§Ù„Ø©ØŒ Ø£Ø¹Ø·Ù Ù†ØªÙŠØ¬Ø© Ù…ÙÙ‡ÙŠÙƒÙ„Ø© Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø· "
        "Ù…Ø¹ Ø§Ù„Ø­Ù‚ÙˆÙ„: type, severity, confidence (0-100), reason, recommendation. "
        "Ø«Ù… Ø§Ù‚ØªØ±Ø­ Ø³Ø¤Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ ÙˆØ§Ø­Ø¯ Ø¥Ø°Ø§ Ø§Ù„Ø«Ù‚Ø© Ø£Ù‚Ù„ Ù…Ù† 90%."
    )
    examples = build_few_shot_examples()
    if examples:
        base += "\n\nØ£Ù…Ø«Ù„Ø© Ù„Ù„ØªØ¹Ù„Ù… (few-shot):\n"
        for i, ex in enumerate(examples, 1):
            base += f"\nÙ…Ø«Ø§Ù„ {i}:\n"
            base += f"Ø§Ù„ÙˆØµÙ: {ex['description']}\n"
            base += f"ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {ex['ai_guess']}\n"
            base += f"ØªØµØ­ÙŠØ­ Ø§Ù„Ù…Ø¯Ø±Ø¨: {ex['correction']}\n"
            base += f"Ø§Ù„Ø³Ø¨Ø¨: {ex['reason']}\n"
    return base

# ----------------- Page styling (kept from original) -----------------
page_css = """
<style>
[data-testid="stAppViewContainer"] > .main {
  background: linear-gradient(180deg, #fff6fb 0%, #fff0f6 100%);
}
.main .block-container {
  background: rgba(255, 255, 255, 0.88);
  border-radius: 12px;
  padding: 1.25rem 1.5rem;
}
.header-title { color: #AD1457; font-weight: 800; font-size:34px; margin:0; }
.header-sub { color: #6b2b3b; margin-top:6px; font-weight:600; }
.stButton>button {
  background: linear-gradient(90deg, #ff9fc0, #ff6fa3);
  color: white;
  border-radius: 10px;
}
[data-testid="stDataFrameContainer"] {
  background: rgba(255,255,255,0.7) !important;
  border-radius: 8px;
  padding: 0.5rem;
}
.signature {
  text-align: center;
  margin-top: 1.25rem;
  font-size: 18px;
  font-weight: 700;
  background: -webkit-linear-gradient(#ff5fa8, #ffd166);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
}
</style>
"""
st.markdown(page_css, unsafe_allow_html=True)

# ----------------- Header -----------------
col1, col2 = st.columns([0.82, 0.18])
with col1:
    st.markdown('<h1 class="header-title">AI Project â€” Trainer by Mohamed Ashraf</h1>', unsafe_allow_html=True)
    st.markdown('<div class="header-sub"><em>Interactive AI trainer: human-in-the-loop defect classification</em></div>', unsafe_allow_html=True)
with col2:
    st.write("")

st.markdown("---")

# ----------------- Main layout -----------------
left, right = st.columns([2, 1])

with left:
    st.header("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹ ÙˆØ¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨")
    st.write("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù…Ø¹ÙŠØ¨ (Ø£Ùˆ Ø§Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§Ù…Ù„Ø© Ø¹Ø¨Ø± Ø²Ø± 'â• Ø¥Ø¶Ø§ÙØ© Ø¹ÙŠØ¨ Ø¬Ø¯ÙŠØ¯').")
    uploaded_file = st.file_uploader("Upload single part image (jpg, jpeg, png) â€” optional", type=["jpg", "jpeg", "png"], key="single_upload")
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, caption="Uploaded image", use_container_width=True)

    # Quick analyze with manual description (if user prefers)
    st.subheader("ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹ â€” Ø§ÙƒØªØ¨ ÙˆØµÙ Ù…Ø®ØªØµØ±")
    quick_desc = st.text_area("ÙˆØµÙ Ø§Ù„Ø­Ø§Ù„Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ):", placeholder="Ø£Ø¯Ø®Ù„ ÙˆØµÙÙ‹Ø§ Ù‚ØµÙŠØ±Ù‹Ø§ Ù„Ù„Ø­Ø§Ù„Ø© Ø¥Ù† ÙˆÙØ¬Ø¯")
    if st.button("Analyze (AI) â€” Quick", key="quick_analyze"):
        if not quick_desc.strip() and not uploaded_file:
            st.warning("Ø£Ø¯Ø®Ù„ ÙˆØµÙ Ø£Ùˆ Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø±Ø¹.")
        else:
            with st.spinner("Generating AI analysis..."):
                system_prompt = compose_system_prompt()
                user_msg = f"ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„ÙˆØµÙÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ©:\n{quick_desc}\n(Ù…Ù„Ø§Ø­Ø¸Ø©: ØµÙˆØ±Ø© Ù…Ø±ÙÙˆØ¹Ø©ØŸ {'Ù†Ø¹Ù…' if uploaded_file else 'Ù„Ø§'})"
                try:
                    response = client.chat.completions.create(
                        model=GPT_MODEL,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_msg}
                        ],
                        max_tokens=700,
                        temperature=0.2,
                    )
                    ai_text = response.choices[0].message.content.strip()
                    st.markdown("**ğŸ¤– AI (structured) â€” response:**")
                    st.code(ai_text, language="json")
                    # Save quick result to results.xlsx
                    save_result(uploaded_file.name if uploaded_file else f"desc_{datetime.now().strftime('%Y%m%d%H%M%S')}", ai_text)
                    st.success("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ results.xlsx")
                    # TTS (optional)
                    try:
                        tts = gTTS(ai_text, lang="ar")
                        tts_path = "ai_response.mp3"
                        tts.save(tts_path)
                        audio_bytes = open(tts_path, "rb").read()
                        st.audio(audio_bytes, format="audio/mp3")
                    except Exception:
                        # ignore TTS errors
                        pass
                    st.session_state["last_ai_text"] = ai_text
                    st.session_state["last_description"] = quick_desc
                except Exception as e:
                    st.error(f"Error communicating with OpenAI: {e}")

    st.markdown("---")
    st.header("â• Ø¥Ø¶Ø§ÙØ© Ø¹ÙŠØ¨ Ø¬Ø¯ÙŠØ¯ (Ø³Ù„ÙŠÙ… vs ØªØ§Ù„Ù) â€” Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ")

    if st.button("â• Ø¥Ø¶Ø§ÙØ© Ø¹ÙŠØ¨ Ø¬Ø¯ÙŠØ¯"):
        st.session_state["add_mode"] = True

    if "add_mode" in st.session_state and st.session_state["add_mode"]:
        with st.form("add_defect_form"):
            col1a, col2a = st.columns(2)
            with col1a:
                defect_name = st.text_input("Ø§Ø³Ù… Ø§Ù„Ø¹ÙŠØ¨:")
                severity = st.selectbox("Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·ÙˆØ±Ø©:", ["Ù…Ù†Ø®ÙØ¶", "Ù…ØªÙˆØ³Ø·", "Ù…Ø±ØªÙØ¹"])
                assembly_done = st.selectbox("Ù‡Ù„ ØªÙ… Ø¹Ù„ÙŠÙ‡ Ø¹Ù…Ù„ÙŠØ© ØªØ¬Ù…ÙŠØ¹ØŸ", ["Ù†Ø¹Ù…", "Ù„Ø§", "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"])
            with col2a:
                package_ok = st.selectbox("Ù‡Ù„ Ø§Ù„Ø¹Ø¨ÙˆØ© Ø³Ù„ÙŠÙ…Ø©ØŸ", ["Ù†Ø¹Ù…", "Ù„Ø§", "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"])
                steps_ok = st.selectbox("Ù‡Ù„ ØªÙ… ØªÙ†ÙÙŠØ° Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ¬Ù…ÙŠØ¹ ÙƒØ§Ù…Ù„Ø©ØŸ", ["Ù†Ø¹Ù…", "Ù„Ø§", "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"])
                description = st.text_area("ÙˆØµÙ Ø§Ù„ØªÙØ§ØµÙŠÙ„ (Ù…Ù‡Ù…):", height=120)

            st.markdown("**Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±**")
            col3, col4 = st.columns(2)
            with col3:
                good_img = st.file_uploader("ØµÙˆØ±Ø© Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø³Ù„ÙŠÙ…", type=["jpg", "jpeg", "png"], key="good_img_upload")
                if good_img:
                    st.image(Image.open(good_img), caption="Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø³Ù„ÙŠÙ…", use_container_width=True)
            with col4:
                defect_img = st.file_uploader("ØµÙˆØ±Ø© Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù…Ø¹ÙŠØ¨", type=["jpg", "jpeg", "png"], key="defect_img_upload")
                if defect_img:
                    st.image(Image.open(defect_img), caption="Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù…Ø¹ÙŠØ¨", use_container_width=True)

            submit_add = st.form_submit_button("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ø¹ÙŠØ¨ ÙˆØªØ­Ù„ÙŠÙ„ AI")

            if submit_add:
                if not description.strip():
                    st.warning("ÙŠØ±Ø¬Ù‰ ÙƒØªØ§Ø¨Ø© ÙˆØµÙ Ù…ÙØµÙ„ Ù„Ù„Ø­Ø§Ù„Ø© Ø­ØªÙ‰ ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ù€ AI Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬ÙŠØ¯.")
                else:
                    # convert images to base64
                    good_b64 = image_to_base64_bytes(good_img) if 'good_img' in locals() else ""
                    defect_b64 = image_to_base64_bytes(defect_img) if 'defect_img' in locals() else ""

                    # Create prompt with few-shot examples
                    system_prompt = compose_system_prompt()
                    user_msg = (
                        f"Ø­Ø§Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„:\n"
                        f"Ø§Ø³Ù… Ø§Ù„Ø¹ÙŠØ¨: {defect_name}\n"
                        f"Ø§Ù„ÙˆØµÙ: {description}\n"
                        f"Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·ÙˆØ±Ø©: {severity}\n"
                        f"ØªÙ… Ø¹Ù„ÙŠÙ‡ ØªØ¬Ù…ÙŠØ¹: {assembly_done}\n"
                        f"Ø§Ù„Ø¹Ø¨ÙˆØ© Ø³Ù„ÙŠÙ…Ø©: {package_ok}\n"
                        f"Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø³Ù„ÙŠÙ…Ø©: {steps_ok}\n"
                        f"(ÙŠÙˆØ¬Ø¯ ØµÙˆØ±ØªÙŠÙ†: Ø¬Ø²Ø¡ Ø³Ù„ÙŠÙ… ÙˆØ¬Ø²Ø¡ ØªØ§Ù„Ù â€” Ø§Ù„ØµÙˆØ± Ù…Ø®Ø²Ù†Ø© Ù…Ø­Ù„ÙŠÙ‹Ø§ ÙÙŠ Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨.)\n"
                        f"Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø·: {{type, severity, confidence (0-100), reason, recommendation}}.\n"
                        f"Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø«Ù‚Ø© Ø£Ù‚Ù„ Ù…Ù† 90% Ø§Ù‚ØªØ±Ø­ Ø³Ø¤Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ ÙˆØ§Ø­Ø¯."
                    )

                    with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ AI..."):
                        try:
                            response = client.chat.completions.create(
                                model=GPT_MODEL,
                                messages=[
                                    {"role": "system", "content": system_prompt},
                                    {"role": "user", "content": user_msg}
                                ],
                                max_tokens=700,
                                temperature=0.2,
                            )
                            ai_text = response.choices[0].message.content.strip()
                        except Exception as e:
                            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ OpenAI: {e}")
                            ai_text = "Error: AI did not respond."

                    # Save to training data with empty correction for now
                    row = {
                        "Ø§Ø³Ù… Ø§Ù„Ø¹ÙŠØ¨": defect_name,
                        "Ø§Ù„ÙˆØµÙ": description,
                        "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·ÙˆØ±Ø©": severity,
                        "ØªÙ… Ø¹Ù„ÙŠÙ‡ ØªØ¬Ù…ÙŠØ¹": assembly_done,
                        "Ø§Ù„Ø¹Ø¨ÙˆØ© Ø³Ù„ÙŠÙ…Ø©": package_ok,
                        "Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø³Ù„ÙŠÙ…Ø©": steps_ok,
                        "image_good_b64": good_b64,
                        "image_defect_b64": defect_b64,
                        "ai_guess": ai_text,
                        "user_correction": "",
                        "correction_reason": "",
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                    save_training_row(row)
                    st.success("âœ… ØªÙ… Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ø¹ Ù†ØªÙŠØ¬Ø© AI. Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ ØªØµØ­ÙŠØ­Ù‡Ø§ ÙÙŠ Ù‚Ø³Ù… 'Ø­ÙˆØ§Ø± Ø§Ù„ØªØ¯Ø±ÙŠØ¨' Ø£Ø¯Ù†Ø§Ù‡.")
                    st.session_state["last_saved_index"] = True

    st.markdown("---")
    st.header("ğŸ—£ï¸ Ø­ÙˆØ§Ø± Ø§Ù„ØªØ¯Ø±ÙŠØ¨ â€” Ø¯Ø±Ù‘ÙØ¨ Ø§Ù„Ù€AI ÙŠØ¯ÙˆÙŠÙ‹Ø§ (Ù…Ø¯Ø±Ù‘Ø¨ â†” Ù…ØªØ¯Ø±Ø¨)")

    # Show latest AI entries that need correction (user_correction empty) or all
    df_train = load_training_data()
    pending = df_train[df_train["user_correction"].isna() | (df_train["user_correction"] == "")]
    st.write(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø³Ø¬Ù„Ø©: {len(df_train)} â€” Ø­Ø§Ù„Ø§Øª Ø¨Ø­Ø§Ø¬Ø© Ù„ØªØµØ­ÙŠØ­: {len(pending)}")

    # Let user pick a pending case to correct (or pick any case)
    choice_mode = st.radio("Ø§Ø®ØªØ± Ø¹Ø±Ø¶ Ø§Ù„Ø­Ø§Ù„Ø§Øª:", ["Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ ØªØµØ­ÙŠØ­", "ÙƒÙ„ Ø§Ù„Ø­Ø§Ù„Ø§Øª"], index=0)
    if choice_mode == "Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ ØªØµØ­ÙŠØ­":
        show_df = pending.reset_index(drop=True)
    else:
        show_df = df_train.reset_index(drop=True)

    if not show_df.empty:
        # display table without big image columns
        st.dataframe(show_df.drop(columns=[c for c in ["image_good_b64", "image_defect_b64"] if c in show_df.columns]))
        sel_idx = st.number_input("Ø§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ø³Ø·Ø± Ù„Ù„ØªØµØ­ÙŠØ­ (index):", min_value=0, max_value=max(0, len(show_df)-1), value=0, step=1)
        sel_row = show_df.loc[sel_idx]
        st.markdown("### Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©")
        st.write(f"**Ø§Ø³Ù… Ø§Ù„Ø¹ÙŠØ¨:** {sel_row.get('Ø§Ø³Ù… Ø§Ù„Ø¹ÙŠØ¨','')}")
        st.write(f"**Ø§Ù„ÙˆØµÙ:** {sel_row.get('Ø§Ù„ÙˆØµÙ','')}")
        st.write(f"**ØªØ­Ù„ÙŠÙ„ AI Ø§Ù„Ø³Ø§Ø¨Ù‚:**")
        st.code(sel_row.get("ai_guess",""))

        # show images if present
        col_a, col_b = st.columns(2)
        with col_a:
            img_good_b64 = sel_row.get("image_good_b64", "")
            if img_good_b64:
                st.image(base64.b64decode(img_good_b64), caption="Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø³Ù„ÙŠÙ…", use_column_width=True)
        with col_b:
            img_def_b64 = sel_row.get("image_defect_b64", "")
            if img_def_b64:
                st.image(base64.b64decode(img_def_b64), caption="Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù…Ø¹ÙŠØ¨", use_column_width=True)

        # Correction input
        st.markdown("#### Ø£Ø¯Ø®Ù„ ØªØµØ­ÙŠØ­Ùƒ ÙƒÙ…Ø¯Ø±Ù‘Ø¨")
        user_correction = st.text_input("Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ØµØ­ÙŠØ­ (Ù…Ø«Ø§Ù„: Ø¹ÙŠØ¨ ØªØ¬Ù…ÙŠØ¹)", key="user_correction_input")
        correction_reason = st.text_area("Ø³Ø¨Ø¨ Ø§Ù„ØªØµØ­ÙŠØ­ (Ø§Ø´Ø±Ø­ Ø¨Ø§Ø®ØªØµØ§Ø±):", key="correction_reason_input")

        if st.button("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„ØªØµØ­ÙŠØ­ ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ…"):
            # update the real dataframe (we used show_df as a view)
            real_df = load_training_data()
            # find the actual row by matching timestamp or description
            # fallback: match first row with same ai_guess & description & empty user_correction
            mask = (real_df["ai_guess"] == sel_row.get("ai_guess")) & (real_df["Ø§Ù„ÙˆØµÙ"] == sel_row.get("Ø§Ù„ÙˆØµÙ"))
            idxs = real_df[mask].index.tolist()
            target_idx = idxs[0] if idxs else None
            if target_idx is None:
                # more robust fallback: try to match by timestamp if present
                ts = sel_row.get("timestamp", "")
                if ts:
                    matched = real_df[real_df["timestamp"] == ts]
                    if not matched.empty:
                        target_idx = matched.index[0]
            if target_idx is None:
                st.error("Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø·Ø± Ø¨Ø¯Ù‚Ù‘Ø© â€” ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø³Ø·Ø± Ø§Ù„ØµØ­ÙŠØ­.")
            else:
                real_df.at[target_idx, "user_correction"] = user_correction
                real_df.at[target_idx, "correction_reason"] = correction_reason
                real_df.at[target_idx, "timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                real_df.to_excel(TRAINING_DATA_PATH, index=False)
                st.success("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØµØ­ÙŠØ­. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ù„ØªØ­Ø³ÙŠÙ† Ø±Ø¯ÙˆØ¯ AI Ù„Ø§Ø­Ù‚Ù‹Ø§ (few-shot).")

    else:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø­Ø§Ù„Ø§Øª Ù„Ù„Ø¹Ø±Ø¶ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ.")

with right:
    st.subheader("Actions â€” Ø¥Ø¯Ø§Ø±Ø© ÙˆÙ†ØªØ§Ø¦Ø¬")
    df = load_results()
    st.write("Total results saved:", len(df))
    if not df.empty:
        st.dataframe(df)
        excel_bytes = results_to_excel_bytes(df)
        st.download_button(
            label="ğŸ“¥ Download results (Excel)",
            data=excel_bytes,
            file_name="results.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    # Training data actions
    st.markdown("---")
    st.subheader("Training data")
    tdf = load_training_data()
    st.write("Total training rows:", len(tdf))
    if not tdf.empty:
        # show table without image columns
        st.dataframe(tdf.drop(columns=[c for c in ["image_good_b64", "image_defect_b64"] if c in tdf.columns]))
        # download button for training data
        buffer = BytesIO()
        tdf.to_excel(buffer, index=False)
        buffer.seek(0)
        st.download_button("ğŸ“¥ Download training_data.xlsx", data=buffer.getvalue(), file_name="training_data.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    if st.button("ğŸ”„ Refresh all"):
        st.experimental_rerun()

    if st.button("ğŸ—‘ï¸ Delete all results"):
        clear_results()
        st.success("âœ… All results have been deleted successfully.")
        st.experimental_rerun()

st.markdown("---")
st.markdown('<div class="signature">âœ¨ Designed by Mohamed Ashraf â€” AI Trainer âœ¨</div>', unsafe_allow_html=True)
